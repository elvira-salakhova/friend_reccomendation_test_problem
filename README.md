# Формулировка задачи:

Вам дан граф неориентированный граф дружб в виде списка ребер. описание колонок: u — идентификатор меньшего пользователя, v — идентификатор большего пользователя, t — время жизни ребра (1 — ребро появилось совсем недавно, 99 — очень давно)
h — абстрактная степень взаимодействия между пользователями.

Задание состоит из 2-х частей:
1) для каждого пользователя, представленного в графе, необходимо составить неупорядоченный список из не более чем 10 рекомендаций. метрика для оценки: recall@10

2) для каждого пользователя из файла user_ids.csv необходимо составить упорядоченный список из не более чем 10 рекомендаций. метрика для оценки: roc_auc_score

# Идеи решений

## Идея I (коллаборативная фильтрация):


- Использовать t для разбивки на тренировочный и тестовый датасеты. Более ранние связи в графе использовать для этапа обучения, а более поздние – для этапа оценки модели. Это позволит избежать data leakage, когда тренировочные данные напрямую связаны с тестовыми. 

- Воспользоваться методом коллаборативной фильтрации, где вместо матрицы user-item, будет матрица user-user. В этой матрице значениями будут абстрактные степени взаимодействия пользователей (столбец h из data_tr.csv). Если взаимодействия нет, то на пересечении строки-пользователя и столбца-пользователя будет ноль. Так как в предложенных данных в столбце h встречаются нули, которые означают минимальное взаимодействие, то необходимо сдвинуть значения h, для того, чтобы отделить минимальные взаимодействия от отсутствия взаимодействия.
- Сформировать предсказания для каждого пользователя путем выбора топ-10 других пользователей по скорам, исключая тех, с которыми уже было взаимодействие. 

## Идея решения II (link prediction):
- Использовать t для разбивки на тренировочный и тестовый датасеты точно так же, как в первой идее решения. 

- Использовать эмбеддинги node2vec для представления узлов в графе. 

- Для пар u,v создать фичи, описывающие связи в графе, путем сложения двух эмбеддингов.

- Данные: сгенерированные фичи и таргет (1/0 - есть связь/нет связи).

- Обучить модель классификации градиентным бустингом (выбрана именно ансамблевая модель, т.к. в таких алгоритмах нет предположения о независимости признаков, а в случае графа дружбы фичи могут быть связаны друг с другом, поэтому нарушается независимость).

- Сформировать пары кандидатов для предсказаний: для каждого пользователя найти 10 ближайших пользователей. Получить предсказания на кандидатах. Отобрать не более 10 пользователей из пар с наибольшим значением предсказания.

- Обработать результат предсказаний и сформировать рекомендации: для каждого пользователя выбрать тех пользователей, для которых значение предсказания не меньше некоторого порога.

- Оценить модель.
- Для второго пункта: с помощью предложенной модели получить рекомендации для пользователей из файла, отсортировать их по предсказанному значению и сформировать рекомендации.

## Библиотеки

Для совместимости библиотек я выбрала python 3.9. При создании python env я использовала следующие версии:
- catboost==1.0.6
- implicit==0.6.1
- networkx==2.6
- node2vec==0.4.6

Для всех  остальных вспомогательных библиотек использовались последние версии.

## Комментарии

Решение выполнено в jupyter notebook. Реализация первой идеи находится в als.ipynb, реализация второй – в link_prediction.ipynb. В процессе реализации идей я написала несколько вспомогательных функций, которые упростили код и сделали его аккуратней. Они находятся в файле utils.py. Для корректной работы ноутбуков папка vk_friends_test_candidate должна находиться на том же уровне, что файлы als.ipynb и link_prediction.ipynb.

В процессе работы я опробовала разные гипотезы для улучшения качества моделей. Например, использовать время жизни дуги в графе и ее вес в совокупности (сумма, произведение, отношение) в качестве веса дуги; использовать knn или другие метрики расстояния для поиска ближайших соседей. Те, что привели к лучшим результатам, отражены в решении. 

Также в процессе решения второй части задания, обнаружилось, что среди пользователей из user_ids.csv есть 15 пользователей, которых нет в предложенном графе. Для формирования рекомендаций для этих пользователей, я использовала простую эвристику: рекомендуем топ-10 самых популярных пользователей (самый популярный - больше всего дуг). 

## Результаты

Наилучший результат для первой части задачи recall@k = 0.22

Наилучший результат для второй части задачи roc_auc_score = 0.95

## Выводы

Качество моделей получилось слабым. Для этого есть несколько причин: недостаточно данных, недостаточно времени на тюнинг параметров моделей. 
Добиться более хорошего решения помогло бы наличие вспомогательных данных о пользователях: пол, возраст, город проживания, интересы и т.п. Тогда в случае со второй идеей решения удалось бы построить эмбеддинги, которые содержали бы в себе больше информации, что привело бы к увеличению значения метрики и улучшению качества рекомендации. Тюнинг параметров также мог бы улучшить качество рекомендаций.

Модель на основе коллаборативной фильтрации оказалась быстрой и выдала более хороший результат, чем модель на основе link prediction для первой части задачи. Однако со второй частью задачи, модель на основе link prediction справилась лучше. Таким образом, в дальнейших экспериментах можно было бы попробовать использовать ALS для подбора кандидатов на рекомендацию, после чего использовать модель link prediction для ранжирования. 
