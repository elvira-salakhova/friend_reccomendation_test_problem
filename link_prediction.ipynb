{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9064d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec as n2v\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from utils import get_test_edges, get_graph, get_links, recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5660c5",
   "metadata": {},
   "source": [
    "## Data preparation, train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23db81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = pd.read_csv(\"vk_friends_test_candidate/data_tr.csv\")\n",
    "full_data = data_tr.drop('t', axis=1)\n",
    "full_data['h'] = full_data['h'] + 1\n",
    "test_edges = get_test_edges(data_tr)\n",
    "full_graph = get_graph(full_data)\n",
    "train_graph = full_graph.copy()\n",
    "train_graph.remove_edges_from(test_edges.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5d2d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test edges ratio: 0.19512847415087742\n"
     ]
    }
   ],
   "source": [
    "print(\"Test edges ratio:\", test_edges.shape[0] / len(full_graph.edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d7adc",
   "metadata": {},
   "source": [
    "## Training a node2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d8d43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00920bc8f778463f9425851b349cf467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/13489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_emb = n2v(train_graph, dimensions=64, walk_length=80, p=1, q=1, num_walks=50, workers=4)\n",
    "\n",
    "WINDOW = 2 \n",
    "MIN_COUNT = 2\n",
    "BATCH_WORDS = 4\n",
    "\n",
    "mdl = g_emb.fit(\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    batch_words=BATCH_WORDS,\n",
    ")\n",
    "\n",
    "# create embeddings dataframe\n",
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [mdl.wv.get_vector(str(n)) for n in train_graph.nodes()],\n",
    "        index = train_graph.nodes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646ebf1",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9607e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_links(G, df, user_id, N):\n",
    "    \"\"\"This function will predict the top N links a node (user_id) should be connected with\n",
    "        which it is not already connected with in G.\n",
    "    \n",
    "    Args:\n",
    "        G (netowrkx.Graph) : The network used to create the embeddings\n",
    "        df (pd.DataFrame) : The dataframe which has embeddings associated to each node\n",
    "        user_id (int) : The user you're interested \n",
    "        N (int) : The number of recommended links you want to return\n",
    "        \n",
    "    Returns:\n",
    "        A list of nodes the input node should be connected with.\n",
    "    \"\"\"\n",
    "    \n",
    "    # separate target user with all others\n",
    "    user = df[df.index == user_id]\n",
    "    \n",
    "    # other users are all users which the current doesn't have an edge connecting\n",
    "    all_nodes = G.nodes()\n",
    "    other_nodes = [n for n in all_nodes if n not in list(G.adj[user_id]) + [user_id]]\n",
    "    other_users = df[df.index.isin(other_nodes)]\n",
    "    # get similarity of current user and all other users\n",
    "    sim = cosine_similarity(user, other_users)[0].tolist()\n",
    "    \n",
    "    idx = other_users.index.tolist()\n",
    "    \n",
    "    # create a similarity dictionary for this user w.r.t all other users\n",
    "    idx_sim = dict(zip(idx, sim))\n",
    "    idx_sim = sorted(idx_sim.items(), key=lambda x: x[1], reverse=True)\n",
    "    similar_users = idx_sim[1:N+1]\n",
    "    users = [art[0] for art in similar_users]\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b44677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_actual = get_links(test_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72403799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1897/1897 [01:17<00:00, 24.34it/s]\n"
     ]
    }
   ],
   "source": [
    "test_users = test_edges.u.unique()\n",
    "dict_predicted = {user: set(predict_links(train_graph, emb_df, user, 10)) for user in  tqdm(test_users)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf409ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10648392198207696"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k(dict_predicted, dict_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0408e116",
   "metadata": {},
   "source": [
    "## Writing to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9add3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13489/13489 [07:21<00:00, 30.54it/s]\n"
     ]
    }
   ],
   "source": [
    "all_users = list(full_graph.nodes()) \n",
    "dict_predicted_all = {user: set(predict_links(train_graph, emb_df, user, 10)) for user in  tqdm(all_users)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06cb291",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recommendation_1_link_pred.txt', 'w') as file:\n",
    "    for key, value in dict_predicted_all.items(): \n",
    "         file.write('%s: %s\\n' % (key,  \", \".join(map(str,value))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0cb252",
   "metadata": {},
   "source": [
    "## Creating training/testing data for gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b83e2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pairs(number_list): \n",
    "    \"\"\"This is an auxiliary function that generates random pairs of number from the given list.\"\"\"\n",
    "    return [number_list[i] for i in random.sample(range(len(number_list)), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6af4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nodes = list(train_graph.nodes())\n",
    "pairs = {tuple(random_pairs(unique_nodes)) for i in range(39000)}\n",
    "pairs = pairs - set(train_graph.edges())\n",
    "non_edges_df = pd.DataFrame(pairs, columns=['u', 'v'])\n",
    "all_possible_edges = set(train_graph.edges()) | pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be6c18ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39124\n"
     ]
    }
   ],
   "source": [
    "# generate edge features for all pairs of nodes\n",
    "edge_features = [\n",
    "    (mdl.wv.get_vector(str(i)) + mdl.wv.get_vector(str(j))) for i,j in all_possible_edges\n",
    "]\n",
    "\n",
    "# get current edges in the network\n",
    "edges = list(train_graph.edges())\n",
    "\n",
    "# create target list, 1 if the pair exists in the network, 0 otherwise\n",
    "is_con = [1 if e in edges else 0 for e in all_possible_edges]\n",
    "\n",
    "print(sum(is_con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ad0ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and target data\n",
    "X = np.array(edge_features)\n",
    "y = is_con\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "  X,\n",
    "  y,\n",
    "  test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25830b",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e3f8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy :  0.9502005632841171\n",
      "Training Accuracy :  0.99654339953912\n",
      "roc_auc: 0.9500527530491852\n",
      "Test Confusion Matrix : \n",
      "[[10843   401]\n",
      " [  766 11424]]\n",
      "Test Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95     11609\n",
      "           1       0.94      0.97      0.95     11825\n",
      "\n",
      "    accuracy                           0.95     23434\n",
      "   macro avg       0.95      0.95      0.95     23434\n",
      "weighted avg       0.95      0.95      0.95     23434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GBC classifier\n",
    "clf = CatBoostClassifier(iterations=100, depth=10, random_state=0, verbose=0)\n",
    "\n",
    "# train the model\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "y_true = y_test\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "x_pred = clf.predict(x_train)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "train_acc = accuracy_score(y_train, x_pred)\n",
    "print(\"Testing Accuracy : \", test_acc)\n",
    "print(\"Training Accuracy : \", train_acc)\n",
    "print(\"roc_auc:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(\"Test Confusion Matrix : \")\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "\n",
    "print(\"Test Classification Report : \")\n",
    "print(classification_report(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6506ac0",
   "metadata": {},
   "source": [
    "## Forming recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0779070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ranked(user_id, predicted):\n",
    "    confidence = []\n",
    "    for pred_user in predicted:\n",
    "        pred_ft = [(mdl.wv.get_vector(str(user_id))+mdl.wv.get_vector(str(pred_user)))]\n",
    "        confidence.append(clf.predict_proba(pred_ft)[0][1])\n",
    "    confidence = np.array(confidence)\n",
    "    predicted = np.array(predicted)\n",
    "    return list(predicted[confidence.argsort()[::-1][:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4f24933",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predicted_ranked = {}\n",
    "for user in test_users:\n",
    "    predicted = predict_links(train_graph, emb_df, user, 50)\n",
    "    dict_predicted_ranked[user] = predict_ranked(user, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5e7083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = pd.read_csv(\"vk_friends_test_candidate/user_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bdb2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_in_graph = set(user_ids.u.values) & set(all_users)\n",
    "new_users = set(user_ids.u.values) - set(all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3a50c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predicted_ranked = {}\n",
    "for user in users_in_graph:\n",
    "    predicted = predict_links(train_graph, emb_df, user, 50)\n",
    "    dict_predicted_ranked[user] = predict_ranked(user, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd39d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_most_popular_users = list(full_data.u.value_counts()[:10].index)\n",
    "for user in new_users:\n",
    "    dict_predicted_ranked[user] = the_most_popular_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17a062",
   "metadata": {},
   "source": [
    "## Writing to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bde1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recommendation_2_link_pred.txt', 'w') as file:\n",
    "    for key, value in dict_predicted_ranked.items(): \n",
    "         file.write('%s: %s\\n' % (key,  \", \".join(map(str,value))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
